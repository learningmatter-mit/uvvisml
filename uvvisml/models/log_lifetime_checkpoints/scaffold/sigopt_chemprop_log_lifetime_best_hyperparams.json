{
    "batch_size": 10,
    "depth": 4,
    "dropout": 0.0,
    "ffn_hidden_size": 750,
    "ffn_num_layers": 3,
    "final_lr": 0.00035111841894230336,
    "hidden_size": 758,
    "init_lr": 0.00035111841894230336,
    "max_lr": 0.00035111841894230336,
    "warmup_epochs": 4
}