{
    "batch_size": 86,
    "depth": 6,
    "dropout": 0.0,
    "ffn_hidden_size": 2400,
    "ffn_num_layers": 3,
    "final_lr": 0.000242923550497919,
    "hidden_size": 1504,
    "init_lr": 0.00013492039003408954,
    "max_lr": 0.000242923550497919,
    "warmup_epochs": 6
}